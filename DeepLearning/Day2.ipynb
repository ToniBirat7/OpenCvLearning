{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of CNN Architectures\n",
    "\n",
    "#### LeNet \n",
    "\n",
    "It was developed for Handwritten Digit Recognition (MNIST Dataset)\n",
    "\n",
    "**Architecture**\n",
    "\n",
    "`Input`: 32x32 grayscale image.\n",
    "\n",
    "`Layers`:\n",
    " - Three convolutional layers followed by average pooling. Used for feature extraction. \n",
    "   - Layer 1 uses six `(5,5)` kernels and stride of 1 i.e. `Output Shape = (32-5+)*(32-5+1)*6 = (28*28*6)`. In the first pooling layer, it converts the `(28*28*6)` feature map to `(14*14*6)` through `2*2` average pooling with stride of `2`, reduces the spatial dimensions (height and width) via average pooling. Then the output is passed to `Hyperbolic Tangent` for the activation function.\n",
    "  \n",
    "   - Layer 2 uses sixteen `(5,5)` kernels and stride of 1 i.e. `Output Shape = (14-5+1)*(14-5+1)*16 = (10*10*16)`. In the second pooling layer, it converts the `(10*10*16)` feature map to `(5*5*16)` through `2*2` average pooling with stride of `2`, reduces the spatial dimensions (height and width) via average pooling. Then the output is passed to `Hyperbolic Tangent` for the activation function. \n",
    "\n",
    "   - Layer 3 (Flatten) uses `120` `(5,5)` kernels and stride of 1 i.e. same as size of the previous feature map the output results in the `Output = (5-5+1,5-5+1,120) = (1,1,120)` feature map which are passed to a fully connected layer. The result is flattened into a `120*1` vector.\n",
    "\n",
    "<img src='../Notes_Images/DL8.png'>\n",
    "\n",
    " - Fully connected layers at the end. Used for classification. Here, it transforms `120-element vector` (Input Layer) to `84-element vector` (Hidden/Dense Layer) and Output Layer matches the number of classes i.e. `10 Neurons`. These `10 Neurons` generate the probability distribution for the classes. \n",
    "\n",
    "`Advantages`:\n",
    "\n",
    " - Reduced the need for manual feature extraction. E.g. using OpenCv libraries to extract features.\n",
    "\n",
    " - Demonstrated the effectiveness of CNNs for image recognition.\n",
    "\n",
    "<style>\n",
    ".bg{\n",
    "\tbackground-color: white;\n",
    "}\n",
    ".mar{\n",
    "\ttext-align: center;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<figure>\n",
    "<img src='../Notes_Images/DL9.svg' class=\"bg\">\n",
    "<figcaption class=\"mar\">LeNet Architecture</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### AlexNet \n",
    "\n",
    "The start of the Deep Learning Revolution. Developed by Geoffrey Hinton in 2012. They started the Deep Learning Revolution by establishing a Deeper 8 layer and wider network. Introduced the `ReLu` activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
